# -*- coding: utf-8 -*-
"""Tugas_Kuliah_AI_12_G6401221013.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QFM_fe4GJjp_Fc0XsFWmVZfQW8Sh8Gj_

HABIB FABRI ARROSYID (G6401221013)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re

from math import log2
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')



"""Link Dataset : https://drive.google.com/file/d/17SOG7TaS1svJgEhKNiYMRs53oMzQPToi/view?usp=sharing

Petunjuk Penggunaan : Upload ke Drive file dataset lalu copy pathnya
"""

df=pd.read_csv('/content/drive/MyDrive/soil_suitability.csv')
df.head()

"""Pendeskripsian Data (Menjelaskan isi keseluruhan data meliputi mean, dan sebagainya)"""

df.describe()

"""Cek kekosongan data"""

df.isna().sum()

"""Cek ukuran data keseluruhan"""

df.shape

"""Melihat tipe data keseluruhan"""

df.info()

def entropy(data, target):
    values, counts = np.unique(data[target], return_counts=True)
    total = sum(counts)
    ent = -sum((counts[i] / total) * log2(counts[i] / total) for i in range(len(values)))
    return ent

def information_gain(data, split_attribute, target):
    total_entropy = entropy(data, target)
    values, counts = np.unique(data[split_attribute], return_counts=True)
    weighted_entropy = sum(
        (counts[i] / sum(counts)) * entropy(data[data[split_attribute] == values[i]], target)
        for i in range(len(values))
    )
    return total_entropy - weighted_entropy

def id3(data, features, target, parent_class=None):
    if len(np.unique(data[target])) == 1:
        return np.unique(data[target])[0]
    elif len(features) == 0:
        return data[target].mode()[0]
    else:
        parent_class = data[target].mode()[0]
        gains = {feature: information_gain(data, feature, target) for feature in features}
        best_feature = max(gains, key=gains.get)
        tree = {best_feature: {}}
        features = [f for f in features if f != best_feature]
        for value in np.unique(data[best_feature]):
            subtree = id3(
                data[data[best_feature] == value], features, target, parent_class
            )
            tree[best_feature][value] = subtree
        return tree

def display_tree(tree, indent=""):
    if isinstance(tree, dict):
        for key, value in tree.items():
            print(f"{indent}{key}")
            display_tree(value, indent + "  ")
    else:
        print(f"{indent}--> {tree}")

def check_label_distribution(data, target):
    print("Distribusi label pada kolom target:")
    print(data[target].value_counts(normalize=True))
    print()

"""#PREPROCESSING"""

df.tail()

"""Import Encoder untuk mengubah data kategorikal menjadi numerikal"""

from sklearn.preprocessing import LabelEncoder

en = LabelEncoder

from sklearn.preprocessing import LabelEncoder
en = LabelEncoder()

"""Pelabelan data kategorikal pada kolom drainage quality"""

d = {'Poor': 0, 'Good': 1}
df['Drainage Quality'] = df['Drainage Quality'].map(d)

df

"""Encoding pada kolom soil texture (berdasarkan random yang berarti urutan abjad, clay=0, loamy = 1, sandy=2)"""

df['Soil Texture'] = en.fit_transform(df['Soil Texture'])

df.head()

df['Suitability'] = df['Suitability'].map({
    'Not Suitable': 0,
    'Suitable': 1
})

df

import numpy as np
from scipy.stats import zscore

df.head()

target = df['Suitability']
target.head(100)

# from sklearn.preprocessing import MinMaxScaler
# scaler = MinMaxScaler()
# numerical_columns = ['pH Level', 'Moisture Content (%)', 'Organic Matter (%)','Drainage Quality','Soil Texture']
# df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

df

df_atribut = df.drop(columns='Suitability')
df_atribut

target

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier

# Split data
x_train, x_test, y_train, y_test = train_test_split(df_atribut, target, test_size=0.45, random_state=500)

# Latih Decision Tree
df_tree = DecisionTreeClassifier(criterion="entropy", random_state=500)
df_tree.fit(x_train, y_train)

print('Akurasi pada data testing : ', df_tree.score(x_test, y_test))

# Visualisasi pohon keputusan
plt.figure(figsize=(20, 10))
plot_tree(
    df_tree,
    feature_names=df_atribut.columns,
    class_names=["Not Suitable", "Suitable"],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Decision Tree Visualisasi", fontsize=16)
plt.show()

"""REPORT UNTUK EVALUASI KINERJA"""

y_pred = df_tree.predict(x_test)
print('Hasil:',classification_report(y_test,y_pred))

"""TEST DATA"""

test_sample = [[6.5, 45, 4.2, 1, 0]]
prediction = df_tree.predict(test_sample)

# Tampilkan hasil prediksi
result = 'Suitable' if prediction[0] == 1 else 'Not Suitable'
print(f"Hasil Prediksi Sampel : {result}")

print('Akurasi:',accuracy_score(y_test,y_pred))

# print('Hasil:',classification_report(Y_test,y_pred))

print(df_tree.predict([[5.9,	72,	5.5,	1,	1]])) #predict tanpa simpulan jawaban cuma 0/1

print(df_tree.predict([[7.5,	56,	5.4,	0,	2]]))

print(df_tree.predict([[7.5,	56,	5.4,	1,	2]]))
test_sample = [[7.5, 56, 5.4, 1, 2]]
prediction = df_tree.predict(test_sample)

# Tampilkan hasil prediksi
result = 'Suitable' if prediction[0] == 1 else 'Not Suitable'
print(f"Hasil Prediksi  Sampel : {result}")

# Model ID3
atribut = list(x_train.columns)
target = 'Suitability'
train_data = pd.concat([x_train, y_train], axis=1)

tree = id3(train_data, atribut, target)

# Pohon keputusan
print("Decision Tree ID3:")
display_tree(tree)

def predict(tree, instance):
    if not isinstance(tree, dict):
        return tree
    atribut = list(tree.keys())[0]
    value = instance[atribut]
    if value in tree[atribut]:
        return predict(tree[atribut][value], instance)
    else:
        return None  # Jika nilai tidak ada dalam pohon

print(f"Akurasi model ID3 pada data uji: ",accuracy_score(y_test,y_pred))

